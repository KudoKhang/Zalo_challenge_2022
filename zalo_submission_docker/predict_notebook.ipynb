{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from networks import get_model\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from loss import *\n",
    "import tqdm\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "import csv\n",
    "import glob\n",
    "\n",
    "from face_detection.OpenVino import OpenVinoModel\n",
    "face_detection = OpenVinoModel(\"./face_detection/models/320x320_25.xml\", input_size=(320, 320))\n",
    "\n",
    "torch.manual_seed(16)\n",
    "np.random.seed(16)\n",
    "random.seed(16)\n",
    "\n",
    "def detect_face(img):\n",
    "    bboxes = face_detection.predict(img)\n",
    "    face_img = img[bboxes[0][1]:bboxes[0][3], bboxes[0][0]:bboxes[0][2]].copy()\n",
    "    return face_img\n",
    "\n",
    "def resize_and_pad(image, size, pad_color=0):\n",
    "    h, w = image.shape[:2]\n",
    "    sh, sw = size\n",
    "\n",
    "    # interpolation method\n",
    "    if h > sh or w > sw:  # shrinking image\n",
    "        interp = cv2.INTER_AREA\n",
    "    else:  # stretching image\n",
    "        interp = cv2.INTER_CUBIC\n",
    "\n",
    "    # aspect ratio of image\n",
    "    aspect = w / h  # if on Python 2, you might need to cast as a float: float(w)/h\n",
    "\n",
    "    # compute scaling and pad sizing\n",
    "    if aspect > 1:  # horizontal image\n",
    "        new_w = sw\n",
    "        new_h = np.round(new_w / aspect).astype(int)\n",
    "        pad_vert = (sh - new_h) / 2\n",
    "        pad_top, pad_bot = np.floor(pad_vert).astype(int), np.ceil(pad_vert).astype(int)\n",
    "        pad_left, pad_right = 0, 0\n",
    "    elif aspect < 1:  # vertical image\n",
    "        new_h = sh\n",
    "        new_w = np.round(new_h * aspect).astype(int)\n",
    "        pad_horz = (sw - new_w) / 2\n",
    "        pad_left, pad_right = np.floor(pad_horz).astype(int), np.ceil(pad_horz).astype(int)\n",
    "        pad_top, pad_bot = 0, 0\n",
    "    else:  # square image\n",
    "        new_h, new_w = sh, sw\n",
    "        pad_left, pad_right, pad_top, pad_bot = 0, 0, 0, 0\n",
    "\n",
    "    # set pad color\n",
    "    if len(image.shape) == 3 and not isinstance(pad_color,\n",
    "                                                (list, tuple, np.ndarray)):  # color image but only one color provided\n",
    "        pad_color = [pad_color] * 3\n",
    "\n",
    "    # scale and pad\n",
    "    scaled_img = cv2.resize(image, (new_w, new_h), interpolation=interp)\n",
    "    scaled_img = cv2.copyMakeBorder(scaled_img, pad_top, pad_bot, pad_left, pad_right,\n",
    "                                    borderType=cv2.BORDER_CONSTANT, value=pad_color)\n",
    "\n",
    "    return scaled_img\n",
    "\n",
    "\n",
    "def normalize(image):\n",
    "    image = image.astype(np.float32)\n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    image /= 255.0\n",
    "    image -= mean\n",
    "    image /= std\n",
    "    return image\n",
    "\n",
    "\n",
    "def preproces(image):\n",
    "    face = resize_and_pad(image, (256, 256))\n",
    "    new_img = normalize(face)\n",
    "    new_img = new_img[:, :, ::-1].transpose((2, 0, 1))\n",
    "    new_img = np.array(new_img)\n",
    "    img2tens = torch.from_numpy(new_img.astype(np.float32)).float()\n",
    "    img2tens = img2tens.cuda().unsqueeze(0)\n",
    "    return img2tens\n",
    "\n",
    "\n",
    "class Inference:\n",
    "    def __init__(self, model):\n",
    "        self.model = get_model(\"SSAN_R\", max_iter=6850000).cuda()\n",
    "        model_ = torch.load(model)\n",
    "        self.model.load_state_dict(model_[\"state_dict\"])\n",
    "        self.model.eval()\n",
    "\n",
    "    def predict(self, img_x):\n",
    "        image_x = preproces(img_x)\n",
    "        cls_x1_x1, _, _, _ = self.model(image_x[:, :, :, :], image_x[:, :, :, :])\n",
    "        score_norm = torch.softmax(cls_x1_x1, dim=1)[:, 1]\n",
    "        return score_norm.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-lesbian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all test cases\n",
    "video_name = []\n",
    "\n",
    "# define the result file\n",
    "if not os.path.exists(\"./result\"):\n",
    "    os.makedirs(\"./result\")\n",
    "\n",
    "\n",
    "result = open(\"./result/jupyter_submission.csv\", \"w\")\n",
    "writer = csv.writer(result)\n",
    "\n",
    "result_time = open(\"./result/time_submission.csv\", \"w\")\n",
    "writer_time = csv.writer(result_time)\n",
    "\n",
    "writer.writerow(['fname', 'liveness_score'])\n",
    "writer_time.writerow(['fname', 'time'])\n",
    "\n",
    "#load video\n",
    "print(f'Load video from: /data/private_test/videos/')\n",
    "for video in glob.glob(\"./data/private_test/videos/*.mp4\"):\n",
    "    video_name.append(video)\n",
    "\n",
    "#load model\n",
    "FAS = Inference(\"./saved_model/SSAN_R_pprivate_epochs_62.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-singing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "for video in tqdm.tqdm(video_name):\n",
    "    t1 = time.time()\n",
    "    score = []\n",
    "    count = 0\n",
    "\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    frame_number = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    for i in range(frame_number):\n",
    "        ret, frame = cap.read()\n",
    "        if count % 3 == 0:\n",
    "            count += 1\n",
    "            try:\n",
    "                face = detect_face(frame)\n",
    "                score.append(FAS.predict(face))\n",
    "            except:\n",
    "                continue\n",
    "        else:\n",
    "            count += 1\n",
    "            continue\n",
    "\n",
    "    cap.release()\n",
    "    # print(score)\n",
    "\n",
    "    if len(score) == 0:\n",
    "        score.append(0)\n",
    "    video_score = [f'{video.split(\"/\")[-1]}', np.mean(score)]\n",
    "    video_time = [f'{video.split(\"/\")[-1]}', f'{int((time.time() - t1) * 1000)}']\n",
    "    writer_time.writerow(video_time)\n",
    "    writer.writerow(video_score)\n",
    "\n",
    "result.close()\n",
    "result_time.close()\n",
    "print(f\"Output is saved in /code/result\")\n",
    "print(\"Done..!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
